{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anissa762/goldfish/blob/main/goldfish4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zHKPE3Lb64R",
        "outputId": "daa155ed-fed4-46be-a0e4-7bc38511c2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AEsbhqycCiB",
        "outputId": "3e0c76d2-17b5-4008-e131-011fd1f23dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (4.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade optuna ta catboost\n",
        "!pip install optuna-integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Rhb8P0srcFA3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import optuna\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ta\n",
        "from catboost import CatBoostRegressor, Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OsLQy27dcJM1"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# User-Defined Parameters\n",
        "#---------------------------------------------\n",
        "DATA_PATH = '/content/drive/MyDrive/data/'\n",
        "ELECTION_DATA_PATH = '/content/drive/MyDrive/final_stock_rankings2.csv'\n",
        "\n",
        "# Prediction horizon (days)\n",
        "TARGET_WINDOW_DAYS = 30\n",
        "\n",
        "# Investment amount\n",
        "TOTAL_INVESTMENT = 30.0\n",
        "\n",
        "# Number of top stocks\n",
        "TOP_N = 5\n",
        "\n",
        "# Prioritize Dec/Jan weighting\n",
        "DEC_JAN_WEIGHT = 2.0  # adjust this factor as needed\n",
        "\n",
        "# Election Date (Assuming US Presidential Election 2024)\n",
        "ELECTION_DATE = datetime(2024, 11, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cV2I3fHNcMaw"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# Load Election Data\n",
        "#---------------------------------------------\n",
        "if os.path.exists(ELECTION_DATA_PATH):\n",
        "    election_data = pd.read_csv(ELECTION_DATA_PATH)\n",
        "else:\n",
        "    raise FileNotFoundError(\"Election impact data not found. Please ensure final_stock_rankings2.csv is in data folder.\")\n",
        "\n",
        "election_data['ElectionImpact'] = election_data['FinalScore']\n",
        "\n",
        "# Keep track of tickers with election data\n",
        "valid_tickers = set(election_data['Ticker'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "QbqNUUYScRno"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# Load and Preprocess Stock Data\n",
        "#---------------------------------------------\n",
        "csv_files = glob.glob(os.path.join(DATA_PATH, '*_data_cleaned.csv'))\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    df = df.copy()\n",
        "    # Moving Averages\n",
        "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "    df['MA50'] = df['Close'].rolling(window=50).mean()\n",
        "    # RSI\n",
        "    df['RSI'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()\n",
        "    # MACD\n",
        "    macd = ta.trend.MACD(df['Close'])\n",
        "    df['MACD'] = macd.macd()\n",
        "    df['MACD_signal'] = macd.macd_signal()\n",
        "    df['MACD_diff'] = macd.macd_diff()\n",
        "    # Bollinger Bands\n",
        "    bollinger = ta.volatility.BollingerBands(df['Close'], window=20, window_dev=2)\n",
        "    df['Bollinger_High'] = bollinger.bollinger_hband()\n",
        "    df['Bollinger_Low'] = bollinger.bollinger_lband()\n",
        "    # Volume MA\n",
        "    df['Volume_MA20'] = df['Volume'].rolling(window=20).mean()\n",
        "    # OBV\n",
        "    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(df['Close'], df['Volume']).on_balance_volume()\n",
        "    # EMAs\n",
        "    df['EMA10'] = ta.trend.EMAIndicator(df['Close'], window=10).ema_indicator()\n",
        "    df['EMA50'] = ta.trend.EMAIndicator(df['Close'], window=50).ema_indicator()\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "stock_data = {}\n",
        "for file in csv_files:\n",
        "    ticker = os.path.basename(file).split('_')[0]\n",
        "    # Only consider tickers that appear in election_data\n",
        "    if ticker not in valid_tickers:\n",
        "        continue\n",
        "    df = pd.read_csv(file)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df.sort_values('Date', inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    df = add_technical_indicators(df)\n",
        "\n",
        "    # Merge ElectionImpact\n",
        "    score_val = election_data.loc[election_data['Ticker'] == ticker, 'ElectionImpact']\n",
        "    if not score_val.empty:\n",
        "        election_impact = score_val.values[0]\n",
        "    else:\n",
        "        # If ticker not found, skip\n",
        "        continue\n",
        "    df['ElectionImpact'] = election_impact\n",
        "\n",
        "    # Additional Date Features\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "\n",
        "    # Post-Election Features\n",
        "    df['DaysSinceElection'] = (df['Date'] - ELECTION_DATE).dt.days\n",
        "    df['PostElection'] = (df['Date'] > ELECTION_DATE).astype(int)\n",
        "\n",
        "    # Future Return as target\n",
        "    df['Future_Close'] = df['Close'].shift(-TARGET_WINDOW_DAYS)\n",
        "    df['Target_Return'] = ((df['Future_Close'] - df['Close']) / df['Close']) * 100\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    stock_data[ticker] = df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nrvdlLiycWH7"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# Combine Data\n",
        "#---------------------------------------------\n",
        "feature_cols = ['Open', 'Close', 'High', 'Low', 'Volume',\n",
        "                'MA10', 'MA50', 'RSI', 'MACD', 'MACD_signal', 'MACD_diff',\n",
        "                'Bollinger_High', 'Bollinger_Low', 'Volume_MA20', 'OBV',\n",
        "                'EMA10', 'EMA50', 'ElectionImpact', 'Month', 'DayOfYear',\n",
        "                'DaysSinceElection', 'PostElection']\n",
        "\n",
        "X_list = []\n",
        "y_list = []\n",
        "weights_list = []\n",
        "\n",
        "for ticker, df in stock_data.items():\n",
        "    if len(df) < (TARGET_WINDOW_DAYS + 1):\n",
        "        continue\n",
        "    X_list.append(df[feature_cols].values)\n",
        "    y_list.append(df['Target_Return'].values)\n",
        "    # Weight samples: December (12) and January (1) get higher weights\n",
        "    sample_weights = np.ones(len(df))\n",
        "    dec_jan_mask = (df['Month'] == 12) | (df['Month'] == 1)\n",
        "    sample_weights[dec_jan_mask] = DEC_JAN_WEIGHT\n",
        "    weights_list.append(sample_weights)\n",
        "\n",
        "X = np.vstack(X_list)\n",
        "y = np.hstack(y_list)\n",
        "sample_weights = np.hstack(weights_list)\n",
        "\n",
        "# Optional: Remove extreme outliers in y to improve stability\n",
        "y_median = np.median(y)\n",
        "y_mad = np.median(np.abs(y - y_median))\n",
        "threshold = 3 * y_mad\n",
        "mask = (np.abs(y - y_median) < threshold)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "sample_weights = sample_weights[mask]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J4avLCgXcZyb"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# Train-Test Split\n",
        "# Using TimeSeriesSplit to simulate historical scenario\n",
        "#---------------------------------------------\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    w_train, w_test = sample_weights[train_index], sample_weights[test_index]\n",
        "\n",
        "# We do NOT scale features by default since CatBoost can handle raw features well.\n",
        "# If needed, we could try scaling again, but let's skip it to see if performance improves.\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTrYSrk1ce1m",
        "outputId": "e004e716-5f94-45f7-9a10-9a74df031447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-12 14:58:03,132] Using an existing study with name 'catboost_hyperparam_tuning2' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold [0/3]\n"
          ]
        }
      ],
      "source": [
        "#---------------------------------------------\n",
        "# Hyperparameter Tuning with Optuna (CatBoost)\n",
        "#---------------------------------------------\n",
        "from catboost import cv as catboost_cv\n",
        "\n",
        "STUDY_DB_PATH = os.path.join(DATA_PATH, 'catboost_study2.db')\n",
        "STUDY_NAME = 'catboost_hyperparam_tuning2'\n",
        "\n",
        "def objective_catboost(trial):\n",
        "    params = {\n",
        "        'iterations': trial.suggest_int('iterations', 500, 3000),\n",
        "        'depth': trial.suggest_int('depth', 4, 12),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.3, log=True),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 15),\n",
        "        'random_strength': trial.suggest_float('random_strength', 1, 10),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10),\n",
        "        'od_wait': 50,\n",
        "        'random_seed': 42,\n",
        "        'loss_function': 'RMSE',\n",
        "        'verbose': False\n",
        "    }\n",
        "\n",
        "    cat_data = Pool(X_train, y_train, weight=w_train)\n",
        "    cv_out = catboost_cv(cat_data, params, fold_count=3, plot=False, verbose=False, early_stopping_rounds=1)\n",
        "    best_rmse = cv_out['test-RMSE-mean'].min()\n",
        "    return best_rmse\n",
        "\n",
        "study = optuna.create_study(\n",
        "    study_name=STUDY_NAME,\n",
        "    storage=f\"sqlite:///{STUDY_DB_PATH}\",\n",
        "    load_if_exists=True,\n",
        "    direction='minimize'\n",
        ")\n",
        "\n",
        "# Increase number of trials and/or time for better search\n",
        "study.optimize(objective_catboost, n_trials=70, timeout=1800000)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    'loss_function': 'RMSE',\n",
        "    'random_seed': 42,\n",
        "    'verbose': False\n",
        "})\n",
        "\n",
        "with open(os.path.join(DATA_PATH, 'best_params_catboost2.pkl'), 'wb') as f:\n",
        "    pickle.dump(best_params, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xas3YgWbcjJ6"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------\n",
        "# Train Final Model with Best Params\n",
        "#---------------------------------------------\n",
        "final_model = CatBoostRegressor(**best_params)\n",
        "\n",
        "final_model.fit(X_train, y_train, sample_weight=w_train, eval_set=(X_test, y_test), use_best_model=True)\n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "final_model.save_model(os.path.join(DATA_PATH, 'final_catboost_model2.cbm'))\n",
        "\n",
        "# Make Predictions for Investment Allocation\n",
        "allocation_candidates = []\n",
        "for ticker, df in stock_data.items():\n",
        "    if len(df) < (TARGET_WINDOW_DAYS + 1):\n",
        "        continue\n",
        "    latest_row = df.iloc[-1]\n",
        "    feat = latest_row[feature_cols].values.reshape(1, -1)\n",
        "    pred_return = final_model.predict(feat)[0]\n",
        "    allocation_candidates.append({\n",
        "        'Stock': ticker,\n",
        "        'Predicted_Return': pred_return\n",
        "    })\n",
        "\n",
        "alloc_df = pd.DataFrame(allocation_candidates)\n",
        "alloc_df.sort_values(by='Predicted_Return', ascending=False, inplace=True)\n",
        "alloc_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "TOP_N = 250\n",
        "top_stocks = alloc_df.head(TOP_N).copy()\n",
        "top_stocks['Investment'] = TOTAL_INVESTMENT / TOP_N\n",
        "top_stocks['Expected_Profit'] = top_stocks['Investment'] * (top_stocks['Predicted_Return'] / 100)\n",
        "\n",
        "print(\"\\n### Investment Allocation ###\\n\")\n",
        "print(top_stocks[['Stock', 'Investment', 'Predicted_Return', 'Expected_Profit']])\n",
        "print(f\"\\nTotal Investment: £{TOTAL_INVESTMENT}\")\n",
        "print(f\"Total Expected Profit: £{top_stocks['Expected_Profit'].sum():.2f}\")\n",
        "\n",
        "# Plot Actual vs. Predicted\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.3)\n",
        "plt.xlabel('Actual Returns (%)')\n",
        "plt.ylabel('Predicted Returns (%)')\n",
        "plt.title('Actual vs. Predicted Returns')\n",
        "plt.plot([y_test.min(), y_test.max()],[y_test.min(), y_test.max()],'r--')\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(residuals, kde=True, bins=50)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residuals (%)')\n",
        "plt.show()\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    non_zero = y_true != 0\n",
        "    y_true = y_true[non_zero]\n",
        "    y_pred = y_pred[non_zero]\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzRZQAczojaq+Tr3WLdqyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}